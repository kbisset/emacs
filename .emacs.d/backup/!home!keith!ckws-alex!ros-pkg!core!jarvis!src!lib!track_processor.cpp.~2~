#include <jarvis/track_processor.h>
#include <jarvis/motion.h>
#include <online_learning/dataset.h>
#include <jarvis/pods.h>
#include <timer/profile.h>
#include <jarvis/track.h>

using namespace Eigen;
using namespace std;

TrackProcessor::TrackProcessor()
{
  // Set up the cmap and augmented prediction label.
  // "Semantic label" - includes only object classes.
  // "Augmented label" - Semantic label + "moving" + "unclear" + "alert"
  applyNameMapping("cmap", acmap());
}

TrackProcessor::TrackProcessor(const std::string& config_file) : TrackProcessor()
{
  YAML::Node config = YAML::LoadFile(config_file.c_str());

  confidence_promote_ =
    std::stof(config["TrackProcessorParams"]["Confidence"]["Promote"].as<std::string>());
  confidence_unclear_ =
    std::stof(config["TrackProcessorParams"]["Confidence"]["Unclear"].as<std::string>());
  motion_threshold_v_ =
    std::stof(config["TrackProcessorParams"]["Motion"]["VerticalThreshold"].as<std::string>());
  motion_threshold_h_ =
    std::stof(config["TrackProcessorParams"]["Motion"]["HorizontalThreshold"].as<std::string>());
  motion_margin_v_ =
    std::stof(config["TrackProcessorParams"]["Motion"]["VerticalMargin"].as<std::string>());
  motion_margin_h_ =
    std::stof(config["TrackProcessorParams"]["Motion"]["HorizontalMargin"].as<std::string>());
  dist_threshold_v_ =
    std::stof(config["TrackProcessorParams"]["Distance"]["VerticalThreshold"].as<std::string>());
  dist_margin_v_ =
    std::stof(config["TrackProcessorParams"]["Distance"]["VerticalMargin"].as<std::string>());
  motion_disable_ =
    config["TrackProcessorParams"]["Motion"]["DisableMotion"].as<bool>();

  ROS_ASSERT(confidence_promote_ > 0);
  ROS_ASSERT(confidence_unclear_ > 0);
}


bool TrackProcessor::isMoving(std::shared_ptr<const Dataset> track) const 
{
  if(!hasBoundingBoxMotion(*track, 0.5) || centroidMotion(*track) < 0.25) {
    ROS_INFO("Filtering out dropped track based on motion");
    return false;
  }
  return true;
}

bool TrackProcessor::isNotTiny(std::shared_ptr<const Dataset> track, std::vector<float>& val) const
{
  int approx_num_samples = 20;
  int step = std::max<int>(1, (float)track->instances_.size() / (float)approx_num_samples);
  int num_large = 0;
  int num_tested = 0;

  for(int i = 0; i < (int)track->instances_.size(); i += step) {
    try {
      const Instance& inst = track->instances_[i];
      static Fatness fatness_pod("Fatness");
      Blob::ConstPtr blob = inst.raw<Blob::ConstPtr>();

      // blob->indices_ are indices into the QVGA depth image.  320x240.
      // If the object is a third the image high and a tenth the image wide then
      // it shouldn't be called small, even if the fatness (i.e. surface area)
      // isn't above threshold.  Numbers derived from videos of Jess's kids.
      float num_pixels = (float) blob->depth_width_/10 * (float) blob->depth_height_/3;
      val[3] += (float)blob->indices_.size();
      if((float)blob->indices_.size() > num_pixels)
        ++num_large;
      else {
        float fatness = fatness_pod.fatness(*blob);
        if(fatness > 0.125)
          ++num_large;
      }
      ++num_tested;
    } catch (...) {
      ROS_WARN_STREAM("Skipping frame " << i << "/" << track->instances_.size() << " in isNotTiny");
    }
  }
  ROS_INFO_STREAM("isNotTiny processed " << num_tested << " frames");
  val[3] /= (float) num_tested;
  
  return ((float)num_large / (float)num_tested > 0.2);
}

bool TrackProcessor::isTall(std::shared_ptr<const Dataset> track) const
{
  int approx_num_samples = 20;
  int step = std::max<int>(1, (float)track->instances_.size() / (float)approx_num_samples);
  int num_tall = 0;
  int num_tested = 0;

  for(int i = 0; i < (int)track->instances_.size(); i += step) {
    try {
    const Instance& inst = track->instances_[i];
    GravitationalCloudOrienter gco_pod("GetSize");
    Blob::ConstPtr blob = inst.raw<Blob::ConstPtr>();
    blob->project(false);
    Eigen::Vector4f size = gco_pod.getSize(*blob);
    float height = size(2);
    if(height > 1.2)
      ++num_tall;
    ++num_tested;
    } catch (...) {
      ROS_WARN_STREAM("Skipping frame " << i << "/" << track->instances_.size() << " in isTall");
    }
  }

  ROS_INFO_STREAM("isTall processed " << num_tested << " frames");
  return ((float)num_tall / (float)num_tested > 0.1);
}

void TrackProcessor::checkDiscontinuity(const std::vector<std::vector<float> >& p_max,
                                        const std::vector<std::vector<float> >& p_min,
                                        const std::vector<std::vector<bool> >& ignore,
                                        const std::vector<float>& fatness,
                                        std::vector<int>& split,
                                        std::vector<std::vector<float> >& val)
{
  const int window(1);
  const float gap(0.4);
  const float min_size[3] = {0.3, 0.3, 0.45};
  float val_acc[4] = {0}, p_size[3] = {0};
  int val_count(0);
  size_t length = p_max[0].size();
  for (size_t i = 0; i < length; i++) {
    bool last = (i == length-1);
    val_count++;
    for (int j = 0; j < 3; j++)
      p_size[j] = p_max[j][i] - p_min[j][i];

    // use min_height if full height is not available (track in top/bottom frame boarder)
    val_acc[2] += (ignore[0][i])? std::fmax(min_size[2], p_size[2]) : p_size[2];

    // use min_width if full width is not available (track in left/right frame boarder)
    val_acc[0] += (ignore[1][i])? std::fmax(min_size[0], p_size[0]) : p_size[0];
    val_acc[1] += (ignore[1][i])? std::fmax(min_size[1], p_size[1]) : p_size[1];

    // average fatness
    val_acc[3] += fatness[i];

    for (int j = 0; j < 3; j++) {
      float diff_max = std::fabs(p_max[j][i] - p_max[j][std::min(i+window,length-1)]);
      float diff_min = std::fabs(p_min[j][i] - p_min[j][std::min(i+window,length-1)]);
      if (diff_max > gap || diff_min > gap || last) {
        split.push_back(i);
        for (int k = 0; k < 4; k++) {
          val[k].push_back(val_acc[k]/static_cast<float>(val_count));
          val_acc[k] = 0;
        }
        val_count = 0;
        break;
      }
    }
  }
}

void TrackProcessor::detectMotionSpeed(const std::vector<std::vector<float> >& p_max,
                                       const std::vector<std::vector<float> >& p_min,
                                       const std::vector<std::vector<bool> >& ignore,
                                       const std::vector<int>& split,
                                       const std::vector<float>& z,
                                       const std::vector<float>& fatness,
                                       const bool isPet,
                                       float* horizontal, float* vertical)
{
  const int step[2] = {20, 20};
  const float fatlimit(0.05);
  float slope[2], theta[2], motion_score_max[2] = {-10, -10};

  // adaptive threshold: running(person, pet), jumping(person, pet)
  const float z_lb[2]  = {0.5, 0.25};
  const float z_ub[2]  = {1.2, 0.45};
  const float th_lb[4] = {0.85, 0.6, 0.3, 0.3};
  const float th_ub[4] = {1.3, 2.40, 0.4, 0.4};
  int c = (isPet)? 1 : 0;

  // precompute slope
  for (int i = 0; i < 2; i++)
    slope[i] = (th_ub[2*i+c] - th_lb[2*i+c])/(z_ub[i] - z_lb[i]);

  // visit a video segment with continuity
  for(int i = 0, offset = 0; i < split.size(); offset = split[i++] + 1) {
    // skip small obj
    if (fatness[i] < fatlimit)
      continue;

    // use adaptive threshold
    for (int j = 0; j < 2; j++)
      theta[j] = std::fmin(std::fmax(slope[j]*(z[i]-z_lb[j])+th_lb[2*j+c],
                                     th_lb[2*j+c]), th_ub[2*j+c]);

    // slide window to the end
    for (int k = 0; k < 2; k++) {
      for (int j = offset; j < split[i] - (step[k] - 1); j++) {
        if (k == 1 && ignore[k][j])
          continue;

        float diff_max, diff_min;
        if (k == 0) {
          float cx1 = (p_max[0][j] + p_min[0][j])/2;
          float cy1 = (p_max[1][j] + p_min[1][j])/2;
          float cx2 = (p_max[0][j+step[k]] + p_min[0][j+step[k]])/2;
          float cy2 = (p_max[1][j+step[k]] + p_min[1][j+step[k]])/2;
          float x1 = p_max[0][j] - p_min[0][j];
          float y1 = p_max[1][j] - p_min[1][j];
          float x2 = p_max[0][j+step[k]] - p_min[0][j+step[k]];
          float y2 = p_max[1][j+step[k]] - p_min[1][j+step[k]];

          float d = std::hypot(cx1-cx2, cy1-cy2);
          float r1 = std::sqrt(x1*x1 + y1*y1)/2;
          float r2 = std::sqrt(x2*x2 + y2*y2)/2;
          diff_max = d + r1 - r2;
          diff_min = d - r1 + r2;
        } else {
          diff_max = p_max[2][j] - p_max[2][j+step[k]];
          diff_min = p_min[2][j] - p_min[2][j+step[k]];
        }

        if (diff_max * diff_min > 0) {
          float score = std::fmin(std::fabs(diff_max), std::fabs(diff_min)) - theta[k];
          motion_score_max[k] = std::fmax(motion_score_max[k], score);
        }
      }
    }
  }
  *horizontal = motion_score_max[0];
  *vertical = motion_score_max[1];
}

void TrackProcessor::detectDistMotion(const std::vector<float>& x_max,
                                      const std::vector<float>& x_min,
                                      std::vector<bool>& ignore,
                                      const std::vector<int>& split,
                                      const std::vector<float>& x,
                                      const float threshold, const float margin,
                                      float* up, float* down)
{
  *up = -10;
  *down = -10;
  // zero ignore if you do not want to use
  // std::fill(ignore.begin(), ignore.end(), 0);

  // each segment
  for(int i = 0, offset = 0; i < split.size(); offset = split[i++] + 1) {
    int length = (split[i] + 1) - offset;

    int arg_max = -1;
    int arg_min = -1;
    float val_max_ = -FLT_MAX;  // top of bb
    float val_max = -FLT_MAX;
    float val_min_ = FLT_MAX;   // top of bb
    float val_min = FLT_MAX;

    // visit every 'step' frame in the segment
    for(int j = offset, step = 1; j < offset + length; j += step) {
      // reject if occluded
      bool not_occluded = x_max[j] - x_min[j] < x[i] + margin &&
                          x_max[j] - x_min[j] > x[i] - margin;
      ignore[j] = ignore[j] || !not_occluded;
      if (ignore[j])
        continue;

      // get highest position
      if (val_max < x_min[j] && val_max_ < x_max[j]) {
        val_max_ = x_max[j];
        val_max = x_min[j];
        arg_max = j;
      }
      // get lowest position
      if (val_min > x_min[j] && val_min_ > x_max[j]) {
        val_min_ = x_max[j];
        val_min = x_min[j];
        arg_min = j;
      }
    }
    if (arg_max == -1 || arg_min == -1)
      continue;

    if (arg_max > arg_min)
      *up = std::fmax(*up, std::fmin(val_max - val_min - threshold, val_max_ - val_min_ - threshold));
    else
      *down = std::fmax(*down, std::fmin(val_max - val_min - threshold, val_max_ - val_min_ - threshold));

    if (*up > 0 && *down > 0)       // motion found, job done
      return;
    else if (*up < 0 && *down < 0)  // cannot find
      continue;


    int arg_max_local = -1;
    int arg_min_local = -1;
    float val_max_local_ = -FLT_MAX;
    float val_max_local = -FLT_MAX;
    float val_min_local_ = FLT_MAX;
    float val_min_local = FLT_MAX;

    // now we have global max and min
    if (arg_max > arg_min) {
      // find another max in [0 arg_min]
      for(int j = offset, step = 1; j < offset + arg_min; j += step) {
        if (ignore[j])
          continue;

        // get highest position
        if (val_max_local < x_min[j] && val_max_local_ < x_max[j]) {
          val_max_local_ = x_max[j];
          val_max_local = x_min[j];
          arg_max_local = j;
        }
      }
      // find another min in [arg_max length]
      for(int j = offset + arg_max + 1, step = 1; j < offset + length; j += step) {
        if (ignore[j])
          continue;

        // get lowest position
        if (val_min_local > x_min[j] && val_min_local_ > x_max[j]) {
          val_min_local_ = x_max[j];
          val_min_local = x_min[j];
          arg_min_local = j;
        }
      }

      if (arg_max_local != -1)
        *down = std::fmax(*down, std::fmin(val_max_local - val_min - threshold, val_max_local - val_min_ - threshold));

      if (arg_min_local != -1)
        *down = std::fmax(*down, std::fmin(val_max - val_min_local - threshold, val_max_ - val_min_local_ - threshold));

    } else {
      // find another min in [0 arg_max]
      for(int j = offset, step = 1; j < offset + arg_max; j += step) {
        if (ignore[j])
          continue;

        // get lowest position
        if (val_min_local > x_min[j] && val_min_local_ > x_max[j]) {
          val_min_local_ = x_max[j];
          val_min_local = x_min[j];
          arg_min_local = j;
        }
      }
      // find another max in [arg_min length]
      for(int j = offset + arg_min + 1, step = 1; j < offset + length; j += step) {
        if (ignore[j])
          continue;

        // get highest position
        if (val_max_local < x_min[j] && val_max_local_ < x_max[j]) {
          val_max_local_ = x_max[j];
          val_max_local = x_min[j];
          arg_max_local = j;
        }
      }

      if (arg_max_local != -1)
        *up = std::fmax(*up, std::fmin(val_max_local - val_min - threshold, val_max_local_ - val_min_ - threshold));

      if (arg_min_local != -1)
        *up = std::fmax(*up, std::fmin(val_max - val_min_local - threshold, val_max_ - val_min_local_ - threshold));
    }
    // motion found, job done
    if (*up > 0 && *down > 0)
      return;
  }
  // cannot find
  return;
}

void TrackProcessor::hasFastMotion(std::shared_ptr<const Dataset> track,
                                   float* vdist, float* vdist_up, float* vdist_down,
                                   float* vertical, float* horizontal, std::vector<float>& val,
                                   bool isPet) const
{
  const int buf_left(5), buf_right(20), buf_top(16), buf_bottom(16);
  const float min_depth(1);
  int num_tested = 0;
  std::vector<std::vector<float> > p_max(3, std::vector<float>(0));
  std::vector<std::vector<float> > p_min(3, std::vector<float>(0));
  std::vector<std::vector<float> > v(4, std::vector<float>(0));
  std::vector<float> fatness;
  std::vector<int> split;
  std::vector<std::vector<bool> > ignore(2, std::vector<bool>(0));

  for(int i = 0; i < (int)track->instances_.size(); i++) {
    try {
      const Instance& inst = track->instances_[i];
      GravitationalCloudOrienter gco_pod("Position");
      Blob::ConstPtr blob = inst.raw<Blob::ConstPtr>();
      blob->project(false);

      static Fatness fatness_pod("Fatness");
      fatness.push_back(fatness_pod.fatness(*blob));

      cv::Rect roi = blob->centeredRoiTight();
      bool too_close = blob->minpt_(2) <= min_depth;
      bool edge_top = roi.y <= buf_top;
      bool edge_bottom = roi.y + roi.height >= blob->depth_height_ - buf_bottom;
      bool edge_left = roi.x <= buf_left;
      bool edge_right = roi.x + roi.width >= blob->depth_width_ - buf_right;
      ignore[0].push_back(edge_top || edge_bottom); // horizontal
      ignore[1].push_back(too_close || edge_left || edge_right); // vertical

      Vector4f maxpt, minpt;
      gco_pod.position(*blob, maxpt, minpt);
      for(int j = 0; j < 3; j++) {
        p_max[j].push_back(maxpt(j));
        p_min[j].push_back(minpt(j));
      }
      num_tested++;
    } catch (...) {
      ROS_WARN_STREAM("Skipping frame " << i << "/" << track->instances_.size() << " in hasFastMotion");
    }
  }
  ROS_INFO_STREAM("hasFastMotion processed " << num_tested << " frames");

  // calculate fatness only for debuggin
  val[4] = std::accumulate(fatness.begin(), fatness.end(), 0.0)/fatness.size();

  // split track at discontinuity point
  checkDiscontinuity(p_max, p_min, ignore, fatness, split, v);

  val[0] = std::accumulate(v[0].begin(), v[0].end(), 0.0)/v[0].size();
  val[1] = std::accumulate(v[1].begin(), v[1].end(), 0.0)/v[1].size();
  val[2] = std::accumulate(v[2].begin(), v[2].end(), 0.0)/v[2].size();

  detectMotionSpeed(p_max, p_min, ignore, split, v[2], v[3], isPet, horizontal, vertical);


  detectDistMotion(p_max[2], p_min[2], ignore[1], split, v[2],
                   dist_threshold_v_, dist_margin_v_, vdist_up, vdist_down);
  *vdist = std::fmax(*vdist_up, *vdist_down);
}

TrackProcessingResult TrackProcessor::process() const
{
  PROFILE_FUNC;
  std::vector<float> debug(5, 0);

  // As everywhere else, this contains log odds, not probabilities.
  // For {yes, no, no answer}, we use log odds of {positive, negative, 0}.
  const NameMapping& cmap = nameMapping("cmap");
  Label apred = VectorXf::Zero(cmap.size());  // "augmented prediction"

  // Determine if the track is moving and record the answer for evaluation.
  // If it's not moving, don't bother proceeding with any other step here.
  // The rest of the backend should drop the track if it's not moving.
  bool is_moving = isMoving(track_->dataset_);
  if(is_moving)
    apred(cmap.toId("moving")) = 1;
  else {
    apred(cmap.toId("moving")) = -1;
    applyLabel(apred);
    return TrackProcessingResult::SUCCESS;
  }


  // Classify the track.  This produces a semantic prediction, i.e. log odds for
  // each object class but not "moving", "unclear", or "alert".
  Label spred = classify(track_->dataset_, 0);  // evenly sampled superimage
  ROS_ASSERT(spred.rows() == 3);
  apred(cmap.toId("person")) = spred(0);
  apred(cmap.toId("pet")) = spred(1);
  apred(cmap.toId("child")) = spred(2);


  // Correct classifier prediction for unrealistic case
  //  - very tall obj is likely to be a person
  bool is_tall = isTall(track_->dataset_);
  if(is_tall)
<<<<<<< HEAD
    apred(cmap.toId("pet")) += -100; // keep confidence val for debugging


  // Finalize classifier prediction based on pos(+)/neg(-) samples such as
  //  (+) sufficiently large object in general
  //  (+) object with a high confidence regardless of its size
  //  (-) object with a low confidence regardless of its size
  //
  //                as is       |<--unclear-->|     as is     |<--clear-->|
  // Pet   |--------------------|------|------|---------------|-----------|
  //     -inf                  0.5     0     0.5              4          inf
  //
  bool is_not_tiny = isNotTiny(track_->dataset_, debug);
  bool is_confident = apred(cmap.toId("pet")) > confidence_promote_;
  bool is_uncertain = fabs(apred(cmap.toId("pet"))) < confidence_unclear_;

  if(is_confident || (is_not_tiny && !is_uncertain))
    apred(cmap.toId("unclear")) = -1;
  else
    apred(cmap.toId("unclear")) = 1;


  // ignore child class unless highly confident
  apred(cmap.toId("child")) -= confidence_promote_;
  if(apred(cmap.toId("person")) > 0 && apred(cmap.toId("child")) <= 0)
    apred(cmap.toId("adult")) = 1;
  else if(apred(cmap.toId("person") > 0) && apred(cmap.toId("child")) > 0)
    apred(cmap.toId("adult")) = -1;
  else {
    apred(cmap.toId("adult")) = -1;
    apred(cmap.toId("child")) += -100;
  }


  // Determine if we should ALERT on this object
  //  (+) anything that are not pets and are clearly recognizable
  if(apred(cmap.toId("pet")) <= 0 && apred(cmap.toId("unclear")) < 0)
=======
    apred(cmap.toId("pet")) = -1*fabs(apred(cmap.toId("pet")));

  // Now determine if we should alert on this object.
  // There is an intermediate step of determining if the object
  // is sufficiently large.  This is broken out and recorded so
  // we can evaluate it independently.
  bool is_large = isLarge(track_->dataset_);
  if(is_large)
    apred(cmap.toId("large")) = 1;
  else
    apred(cmap.toId("large")) = -1;

  // Do not filter out the small object with a high confidence.
  // We expect to see that this type of object is not super tiny but still
  // clearly recognizable by the classifier
  bool is_confident = fabs(apred(cmap.toId("pet"))) > 4.0;
  if(is_confident)
    apred(cmap.toId("large")) = 1;

  // Be careful about the prediction with a low confidence
  // cascaded classifier would be good for this type of tracks in the future
  bool is_uncertain = fabs(apred(cmap.toId("pet"))) < 0.5;
  if(is_uncertain)
    apred(cmap.toId("large")) = -1;  // uncertain track considered as a small obj

  // Currently, alerts are anything that are not pets and are sufficiently large.
  // This will grow in complexity later, e.g. once we have a human classifier,
  // objects recognized as humans will always be alerts.
  if(apred(cmap.toId("pet")) <= 0 && apred(cmap.toId("large")) > 0)
>>>>>>> J2-A: Add penguin compatibility - requires different cfg file
    apred(cmap.toId("alert")) = 1;
  else
    apred(cmap.toId("alert")) = -1;


  // assign other class if none of them was found
  // (currently only performance monitoring purpose)
  if(apred(cmap.toId("person")) <= 0 && apred(cmap.toId("pet")) <= 0 &&
     apred(cmap.toId("child")) <= 0)
    apred(cmap.toId("other")) =
      fabs(fmax(apred(cmap.toId("person")),
           fmax(apred(cmap.toId("pet")), apred(cmap.toId("child")))));
  else
    apred(cmap.toId("other")) = -1;


  // Understand characteristics of the moving object (jumping, running)
  if (!motion_disable_)
    hasFastMotion(track_->dataset_,
      &apred(cmap.toId("vertical_distance")),
      &apred(cmap.toId("vertical_distance_up")),
      &apred(cmap.toId("vertical_distance_down")),
      &apred(cmap.toId("vertical_motion")),
      &apred(cmap.toId("horizontal_motion")), debug,
      (apred(cmap.toId("alert")) == -1));


  // export some values for debugging
  apred(cmap.toId("x")) = debug[0];
  apred(cmap.toId("y")) = debug[1];
  apred(cmap.toId("z")) = debug[2];
  apred(cmap.toId("px")) = debug[3];
  apred(cmap.toId("fat")) = debug[4];


  // all labels need to be filled out at this point. To make it clear,
  // user-facing labels must be set in track_publisher, not track_processor.
  applyLabel(apred);
  return TrackProcessingResult::SUCCESS;
}

const NameMapping& TrackProcessor::acmap()
{
  static NameMapping acmap;
  if(acmap.empty()) {
    acmap.addName("unclear");
    acmap.addName("person");
    acmap.addName("pet");
    acmap.addName("child");
    acmap.addName("other");
    acmap.addName("adult");
    acmap.addName("moving");
    acmap.addName("alert");
    acmap.addName("vertical_motion");
    acmap.addName("vertical_distance");
    acmap.addName("vertical_distance_up");
    acmap.addName("vertical_distance_down");
    acmap.addName("horizontal_motion");
    acmap.addName("x");
    acmap.addName("y");
    acmap.addName("z");
    acmap.addName("px");
    acmap.addName("fat");
  }
  return acmap;
}

cv::Vec3b TrackProcessor::labelToColor(const Label& apred)
{
  const NameMapping& cmap = acmap();
//  ROS_ASSERT((size_t)apred.rows() == cmap.size());

  // TODO: the colors should be defined and made available in one spot
  // Note all here colors are BGR
  if(apred(cmap.toId("alert")) > 0)
    return cv::Vec3b(0xE2, 0x90, 0x4A); // andreas Blue
    // cv::Vec3b(0, 0, 255);  // red

  // We're not doing well on very small objects.
  // For these, show that we know they're not threats, even
  // if we don't really know what they are.
  // *** NOTE: This needs to agree with the value in TrackEncoder::encodeInstances()
  if(apred(cmap.toId("unclear")) > 0)
    return cv::Vec3b(192, 192, 192);  // gray
    // return cv::Vec3b(0xC2, 0xE3, 0x50   ); // andreas Teal

  // Large pets
  if(apred(cmap.toId("pet")) > 0)
    return cv::Vec3b(0x1C, 0xA1, 0xF9);  // andreas Orange
    //  return cv::Vec3b(0, 255, 0);  // green

//  if((cmap.hasId("kids") && apred(cmap.toId("kids")) > 0) ||
//     (cmap.hasId("kid") && apred(cmap.toId("kid")) > 0) ||
//     (cmap.hasId("child") && apred(cmap.toId("child")) > 0) ||
//     (cmap.hasId("children") && apred(cmap.toId("children")) > 0) > 0)
//    return cv::Vec3b(0x21, 0xD3, 0x7E);  // andreas Green

  // We shouldn't even get here.
  // Orange is for debugging.
  // It indicates that e.g. a Label has been accidentally set to all 0s.
  return cv::Vec3b(0, 140, 255);  // orange
}

std::set<std::string> TrackProcessor::labelToStrings(const Label& apred)
{
  const NameMapping& cmap = acmap();
  ROS_ASSERT(apred.rows() > 0);  // For more granular debugging with only a stack trace.
//  ROS_ASSERT(cmap.size() == (size_t)apred.rows());

  set<std::string> strings;
  for(size_t i = 0; i < cmap.size(); ++i)
    if(apred.coeffRef(i) > 0)
      strings.insert(cmap.toName(i));

  return strings;
}

void TrackProcessor::applyLabel(Label label) const
{
  // Apply the augmented prediction to track_.
  // For some reason there are now multiple ways to do this,
  // so do all of them just in case.
  track_->overall_label_.reset(new Label(label));
  track_->dataset_->applyNameMapping("cmap", nameMapping("cmap"));
  track_->dataset_->setLabel(label);
}


void TrackProcessor::_applyNameTranslator(const std::string& nmid,
                                          const NameTranslator& translator)
{
}
